# General 
model_name_or_path: ../models/gemma-2-2b-it
# model_name_or_path: ../hugging_cache/llama-7b
torch_dtype: bfloat16
device: cuda:0
seed: 42   
use_chat_template: true
system_prompt: ''  

# Generate Vector 
# The `steer_train_hparam_paths` and `steer_train_dataset` are corresponding line by line.
steer_train_hparam_paths:
 - hparams/Steer/caa_hparams/generate_caa_axbench.yaml
steer_train_dataset: axbench
save_vectors: False
steer_vector_output_dir: steer/vectors/gemma-2-2b-it/

# Apply Vector 
# The `apply_steer_hparam_paths` and `steer_vector_load_dir` are corresponding line by line.
apply_steer_hparam_paths:
 - hparams/Steer/caa_hparams/apply_caa_axbench.yaml
steer_vector_load_dir: 
 - steer/vectors/gemma-2-2b-it/axbench/caa_vector

# Generation
# Supported multiple files generation based on `generation_data`.
generation_data: 
 - axbench
generation_data_size: 100
generation_output_dir: steer/logs/gemma-2-2b-it/
num_responses: 1
steer_from_end_position: false

generate_orig_output: false
generation_params:      #change
  max_new_tokens: 128   
  temperature: 1.0       
  do_sample: true  

